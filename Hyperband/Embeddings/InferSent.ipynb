{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a4b69c-1808-4590-a327-efe3fa71a2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11798cc4-90cd-487a-a337-ab2fc826c546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e32df752-7f24-40ff-b5ed-b98200af4eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "allfiles = []\n",
    "for root, dirs, files in os.walk(\"/home/ubuntu/AutoLDA/Code/Transcripts/\", topdown=False):\n",
    "    for name in files:\n",
    "        if name.endswith(\".txt\") and \"checkpoint\" not in name:\n",
    "            allfiles.append(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca327383-9db9-41c5-bc04-935fdd638e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "555"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1dff560-390b-4db7-8dd7-f703c48b0aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllText(allfiles):\n",
    "    res = []\n",
    "    for file in allfiles:\n",
    "        with open(file,\"r\") as f:\n",
    "            res.append(f.read())\n",
    "    return \" \".join(res)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1991bfd8-be75-4c13-8c9f-f8fe7a1854b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "allText = getAllText(allfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea0e0aaf-8ba2-4b58-b833-d0f1aa4b28ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5081360"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "227a46fa-6c7f-4140-8ad7-dee84b2955ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  hey you guys welco'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allText[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d8d220c-e2ac-46ee-91f5-88fb7af733df",
   "metadata": {},
   "outputs": [],
   "source": [
    "processedText = allText.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94fb6b6e-a6c0-4696-a032-87ce1adbfdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey', 'you', 'guys', 'welcome', 'back', 'to', 'my', 'channel', 'is', 'your']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processedText[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05e26829-2f86-4b98-8999-050dadc510d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://github.com/facebookresearch/InferSent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "439a99e6-408d-47d5-8250-0ea6d66fbed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b16e1b94-194b-471b-9c07-9f8949209afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stuff\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72a70c89-dc84-4e17-bbfb-cfe112320395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "from InferSent.models import InferSent\n",
    "model_version = 1\n",
    "MODEL_PATH = \"InferSent/infersent%s.pkl\" % model_version\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': model_version}\n",
    "model = InferSent(params_model)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d540aefa-c88d-4fe0-b761-a5b29bf2b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep it on CPU or put it on GPU\n",
    "use_cuda = False\n",
    "model = model.cuda() if use_cuda else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba7b05f5-c813-4f1c-ac6c-83d9d2dfd562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If infersent1 -> use GloVe embeddings. If infersent2 -> use InferSent embeddings.\n",
    "W2V_PATH = 'GloveFineTune/glove.840B.300d.txt' if model_version == 1 else 'fastText/crawl-300d-2M.vec'\n",
    "model.set_w2v_path(W2V_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f70329f-8384-4da2-91e5-72dd3e0b253e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size : 100000\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings of K most frequent words\n",
    "model.build_vocab_k_words(K=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "367c3498-b86e-47c8-baf6-aec13ab581ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load some sentences\n",
    "# sentences = []\n",
    "# with open('samples.txt') as f:\n",
    "#     for line in f:\n",
    "#         sentences.append(line.strip())\n",
    "# print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dddbc9b-cfa4-4db6-88eb-521026755f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences =  allText.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "020563f5-c9ae-4d9c-b7db-88768c214b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1893"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dde71cf6-c5ad-40cd-8b8c-14cf9b920e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13108404,  0.0095878 ,  0.00454948, ...,  0.02293484,\n",
       "        -0.03814263, -0.01252607]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encode(['the cat eats.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5c56056-9bf4-4817-8f8e-fe447ed10f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutS = [s[:max(len(s),20)] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f98e8d9f-111b-4512-8ff1-3a337e26c672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb words kept : 24339/25879 (94.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/AutoLDA/Code/Embeddings/InferSent/models.py:207: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sentences = np.array(sentences)[idx_sort]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed : 0.7 sentences/s (cpu mode, bsize=128)\n",
      "nb sentences encoded : 20\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(cutS[:20], bsize=128, tokenize=False, verbose=True)\n",
    "print('nb sentences encoded : {0}'.format(len(embeddings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20316442-5a27-4eee-9899-634a0a43a1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4096)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "689fe348-a2b6-4a38-952d-3ab8004b48a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5349097"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(model.encode(['the cat eats.']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e2864f-7a20-48b6-9f51-140d9d73feb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://github.com/facebookresearch/InferSent/blob/main/demo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6199451-98a6-4cd2-9abb-c45b8df158bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-7422fa3a1e8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInferSent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mMODEL_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'InferSent/infersent%s.pkl'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n\u001b[1;32m      5\u001b[0m                 'pool_type': 'max', 'dpout_model': 0.0, 'version': V}\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "from models import InferSent\n",
    "V = 1\n",
    "MODEL_PATH = 'InferSent/infersent%s.pkl' % V\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': V}\n",
    "infersent = InferSent(params_model)\n",
    "infersent.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984db225-fe4b-49b9-a79e-1e82047c9dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
